#!/usr/bin/env python3
"""
LeRobot æ•°æ®æ ¼å¼çš„å¼‚æ­¥æ¨ç†è§‚å¯Ÿå™¨
ç›´æ¥ä½¿ç”¨ inference engine,æ— éœ€ WebSocket æœåŠ¡å™¨
"""

import asyncio
from collections.abc import Callable
import json
import logging
from pathlib import Path
import time
import traceback
from typing import Any

from async_pi05_inference import AsyncPi05Inference
import h5py
import numpy as np

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class LeRobotInferenceObserver:
    """LeRobot æ•°æ®æ ¼å¼çš„å¼‚æ­¥æ¨ç†è§‚å¯Ÿå™¨"""

    def __init__(self, config_name: str = "right_pi05_20", gpu_id: int = 1, output_dir: str = "./inference_outputs"):
        self.inference_engine = AsyncPi05Inference(config_name=config_name, gpu_id=gpu_id)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.observation_callbacks: list[Callable] = []
        self._initialized = False

    async def initialize(self):
        """åˆå§‹åŒ–æ¨ç†å¼•æ“"""
        if not self._initialized:
            await self.inference_engine.initialize()
            self._initialized = True
            logger.info("æ¨ç†å¼•æ“åˆå§‹åŒ–å®Œæˆ")

    def load_lerobot_episode(self, episode_path: str, frame_idx: int = 0) -> dict[str, Any]:
        """åŠ è½½ LeRobot æ ¼å¼çš„ episode æ•°æ®"""
        episode_data = {}

        try:
            # å°è¯•åŠ è½½ HDF5 æ–‡ä»¶
            if episode_path.endswith((".hdf5", ".h5")):
                with h5py.File(episode_path, "r") as f:
                    # åŠ è½½å›¾åƒæ•°æ®
                    image_keys = ["base", "left_wrist", "right_wrist"]
                    for key in image_keys:
                        if key in f:
                            episode_data[key] = np.array(f[key])

                    # åŠ è½½çŠ¶æ€æ•°æ®
                    if "state" in f:
                        episode_data["state"] = np.array(f["state"])

                    # åŠ è½½åŠ¨ä½œæ•°æ®
                    if "actions" in f:
                        episode_data["actions"] = np.array(f["actions"])

                    # åŠ è½½å…ƒæ•°æ®
                    if "meta" in f:
                        episode_data["meta"] = dict(f["meta"].attrs)

            # å°è¯•åŠ è½½ JSONL æ–‡ä»¶
            elif episode_path.endswith(".jsonl"):
                with open(episode_path) as f:
                    for line in f:
                        data = json.loads(line.strip())
                        episode_data.update(data)

            logger.info(f"æˆåŠŸåŠ è½½ LeRobot episode: {episode_path}")
            logger.info(f"æ•°æ®é”®: {list(episode_data.keys())}")

        except Exception as e:
            logger.error(f"åŠ è½½ LeRobot episode å¤±è´¥: {e}")
            # è¿”å›æ¨¡æ‹Ÿæ•°æ®
            episode_data = self._create_fake_lerobot_data()

        return episode_data

    def create_fake_lerobot_data(self) -> dict[str, Any]:
        """åˆ›å»ºæ¨¡æ‹Ÿçš„ LeRobot æ•°æ®"""
        return {
            "base": np.random.randint(0, 255, (10, 224, 224, 3), dtype=np.uint8),
            "left_wrist": np.random.randint(0, 255, (10, 224, 224, 3), dtype=np.uint8),
            "right_wrist": np.random.randint(0, 255, (10, 224, 224, 3), dtype=np.uint8),
            "state": np.random.randn(10, 32).astype(np.float32),
            "actions": np.random.randn(10, 50, 32).astype(np.float32),
            "high_level_prompt": "Pick up the red block and place it in the box",
            "low_level_prompt": "Move to the red block, grasp it, lift it up, move to the box, place it down",
        }

    def prepare_images_from_lerobot(self, episode_data: dict[str, Any], frame_idx: int = 0) -> dict[str, np.ndarray]:
        """ä» LeRobot æ•°æ®å‡†å¤‡å›¾åƒ"""
        images = {}
        lerobot_to_inference_keys = {
            "base": "base_0_rgb",
            "left_wrist": "left_wrist_0_rgb",
            "right_wrist": "right_wrist_0_rgb",
        }

        for lerobot_key, inference_key in lerobot_to_inference_keys.items():
            if lerobot_key in episode_data:
                img_data = episode_data[lerobot_key]

                # å¤„ç†ä¸åŒå½¢çŠ¶çš„å›¾åƒæ•°æ®
                if len(img_data.shape) == 4:  # (T, H, W, C)
                    img = img_data[frame_idx]
                elif len(img_data.shape) == 3:  # (H, W, C)
                    img = img_data
                else:
                    logger.warning(f"ä¸æ”¯æŒçš„å›¾åƒå½¢çŠ¶: {img_data.shape}")
                    img = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)

                # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
                if img.dtype != np.uint8:
                    img = (img * 255).astype(np.uint8) if img.max() <= 1.0 else img.astype(np.uint8)

                images[inference_key] = img
                logger.info(f"å‡†å¤‡å›¾åƒ: {inference_key}, å½¢çŠ¶: {img.shape}")
            else:
                # å¦‚æœç¼ºå°‘å›¾åƒ,ä½¿ç”¨éšæœºå›¾åƒ
                images[inference_key] = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
                logger.warning(f"ç¼ºå°‘ {lerobot_key} å›¾åƒ,ä½¿ç”¨éšæœºå›¾åƒ")

        return images

    def prepare_state_from_lerobot(self, episode_data: dict[str, Any], frame_idx: int = 0) -> np.ndarray | None:
        """ä» LeRobot æ•°æ®å‡†å¤‡çŠ¶æ€"""
        if "state" in episode_data:
            state_data = episode_data["state"]
            if len(state_data.shape) == 2:  # (T, state_dim)
                return state_data[frame_idx]
            if len(state_data.shape) == 1:  # (state_dim,)
                return state_data
            logger.warning(f"ä¸æ”¯æŒçš„çŠ¶æ€å½¢çŠ¶: {state_data.shape}")
            return np.random.randn(32).astype(np.float32)
        logger.warning("LeRobot æ•°æ®ä¸­ç¼ºå°‘çŠ¶æ€ä¿¡æ¯,ä½¿ç”¨éšæœºçŠ¶æ€")
        return np.random.randn(32).astype(np.float32)

    def add_observation_callback(self, callback: Callable[[dict[str, Any]], None]):
        """æ·»åŠ è§‚å¯Ÿå›è°ƒå‡½æ•°"""
        self.observation_callbacks.append(callback)

    async def _notify_observers(self, data: dict[str, Any]):
        """é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…"""
        for callback in self.observation_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(data)
                else:
                    callback(data)
            except Exception as e:
                logger.error(f"è§‚å¯Ÿå›è°ƒå‡ºé”™: {e}")

    async def observe_single_inference(
        self,
        episode_data: dict[str, Any],
        frame_idx: int = 0,
        high_level_prompt: str | None = None,
        low_level_prompt: str | None = None,
        *,
        generate_subtask: bool = True,
        max_decoding_steps: int = 25,
        temperature: float = 0.1,
    ) -> dict[str, Any]:
        """è§‚å¯Ÿå•æ¬¡æ¨ç†"""
        await self.initialize()

        # å‡†å¤‡æ•°æ®
        images = self.prepare_images_from_lerobot(episode_data, frame_idx)
        state = self.prepare_state_from_lerobot(episode_data, frame_idx)

        # ä½¿ç”¨ LeRobot æ•°æ®ä¸­çš„ prompt æˆ–æä¾›çš„ prompt
        if high_level_prompt is None:
            high_level_prompt = episode_data.get("high_level_prompt", "Complete the manipulation task")
        if low_level_prompt is None:
            low_level_prompt = episode_data.get("low_level_prompt", "Execute the planned sequence")

        logger.info(f"å¼€å§‹å•æ¬¡æ¨ç†è§‚å¯Ÿ (frame {frame_idx}):")
        logger.info(f"  é«˜çº§ä»»åŠ¡: {high_level_prompt}")
        logger.info(f"  ä½çº§ä»»åŠ¡: {low_level_prompt}")

        # æ‰§è¡Œæ¨ç†
        start_time = time.time()
        result = await self.inference_engine.infer(
            images=images,
            high_level_prompt=high_level_prompt,
            low_level_prompt=low_level_prompt,
            state=state,
            generate_subtask=generate_subtask,
            max_decoding_steps=max_decoding_steps,
            temperature=temperature,
        )
        inference_time = time.time() - start_time

        # æ„å»ºè§‚å¯Ÿæ•°æ®
        observation_data = {
            "timestamp": time.time(),
            "frame_idx": frame_idx,
            "inference_time": inference_time,
            "result": result,
            "images_shape": {k: v.shape for k, v in images.items()},
            "state_shape": state.shape if state is not None else None,
            "high_level_prompt": high_level_prompt,
            "low_level_prompt": low_level_prompt,
        }

        # é€šçŸ¥è§‚å¯Ÿè€…
        await self._notify_observers(observation_data)

        # ä¿å­˜ç»“æœ
        await self._save_observation(observation_data)

        logger.info(f"æ¨ç†å®Œæˆ,è€—æ—¶: {inference_time:.3f}s")
        if result.get("subtask"):
            logger.info(f"ç”Ÿæˆçš„å­ä»»åŠ¡: {result['subtask']}")

        return observation_data

    async def observe_continuous_inference(
        self,
        episode_data: dict[str, Any],
        start_frame: int = 0,
        max_frames: int = 10,
        frame_interval: float = 1.0,
        high_level_prompt: str | None = None,
        low_level_prompt: str | None = None,
        subtask_refresh_interval: float | None = None,
    ) -> list[dict[str, Any]]:
        """æŒç»­è§‚å¯Ÿæ¨ç†è¿‡ç¨‹"""
        await self.initialize()

        observations = []
        current_frame = start_frame

        logger.info("å¼€å§‹æŒç»­æ¨ç†è§‚å¯Ÿ:")
        logger.info(f"  èµ·å§‹å¸§: {start_frame}")
        logger.info(f"  æœ€å¤§å¸§æ•°: {max_frames}")
        logger.info(f"  å¸§é—´éš”: {frame_interval}s")
        logger.info(f"  å­ä»»åŠ¡åˆ·æ–°é—´éš”: {subtask_refresh_interval}s")

        # å‡†å¤‡åˆå§‹æ•°æ®
        images = self.prepare_images_from_lerobot(episode_data, current_frame)
        state = self.prepare_state_from_lerobot(episode_data, current_frame)

        if high_level_prompt is None:
            high_level_prompt = episode_data.get("high_level_prompt", "Complete the manipulation task")
        if low_level_prompt is None:
            low_level_prompt = episode_data.get("low_level_prompt", "Execute the planned sequence")

        # æ‰§è¡Œåˆå§‹æ¨ç†
        logger.info("æ‰§è¡Œåˆå§‹æ¨ç†...")
        initial_result = await self.inference_engine.infer(
            images=images,
            high_level_prompt=high_level_prompt,
            low_level_prompt=low_level_prompt,
            state=state,
            generate_subtask=True,
            subtask_refresh_interval=subtask_refresh_interval,
        )

        initial_observation = {
            "timestamp": time.time(),
            "frame_idx": current_frame,
            "inference_time": 0,
            "result": initial_result,
            "images_shape": {k: v.shape for k, v in images.items()},
            "state_shape": state.shape if state is not None else None,
            "high_level_prompt": high_level_prompt,
            "low_level_prompt": low_level_prompt,
            "is_initial": True,
        }

        observations.append(initial_observation)
        await self._notify_observers(initial_observation)
        await self._save_observation(initial_observation)

        # æŒç»­è§‚å¯Ÿ
        for frame_idx in range(start_frame + 1, min(start_frame + max_frames, len(episode_data.get("base", [])))):
            try:
                await asyncio.sleep(frame_interval)

                # å‡†å¤‡å½“å‰å¸§æ•°æ®
                current_images = self.prepare_images_from_lerobot(episode_data, frame_idx)
                current_state = self.prepare_state_from_lerobot(episode_data, frame_idx)

                # æ‰§è¡Œæ¨ç†
                start_time = time.time()
                result = await self.inference_engine.infer(
                    images=current_images,
                    high_level_prompt=high_level_prompt,
                    low_level_prompt=low_level_prompt,
                    state=current_state,
                    generate_subtask=True,
                )
                inference_time = time.time() - start_time

                # æ„å»ºè§‚å¯Ÿæ•°æ®
                observation = {
                    "timestamp": time.time(),
                    "frame_idx": frame_idx,
                    "inference_time": inference_time,
                    "result": result,
                    "images_shape": {k: v.shape for k, v in current_images.items()},
                    "state_shape": current_state.shape if current_state is not None else None,
                    "high_level_prompt": high_level_prompt,
                    "low_level_prompt": low_level_prompt,
                    "is_initial": False,
                }

                observations.append(observation)
                await self._notify_observers(observation)
                await self._save_observation(observation)

                logger.info(f"å¸§ {frame_idx} æ¨ç†å®Œæˆ,è€—æ—¶: {inference_time:.3f}s")
                if result.get("subtask"):
                    logger.info(f"ç”Ÿæˆçš„å­ä»»åŠ¡: {result['subtask']}")

            except Exception as e:
                logger.error(f"å¸§ {frame_idx} æ¨ç†å¤±è´¥: {e}")
                continue

        logger.info(f"æŒç»­è§‚å¯Ÿå®Œæˆ,å…±å¤„ç† {len(observations)} å¸§")
        return observations

    async def _save_observation(self, observation: dict[str, Any]):
        """ä¿å­˜è§‚å¯Ÿæ•°æ®"""
        timestamp = int(observation["timestamp"])
        frame_idx = observation["frame_idx"]

        # ä¿å­˜ä¸º JSON æ–‡ä»¶
        output_file = self.output_dir / f"observation_{timestamp}_{frame_idx}.json"

        # å‡†å¤‡å¯åºåˆ—åŒ–çš„æ•°æ®
        serializable_data = {
            "timestamp": observation["timestamp"],
            "frame_idx": observation["frame_idx"],
            "inference_time": observation["inference_time"],
            "result": {
                "actions": observation["result"]["actions"].tolist()
                if observation["result"]["actions"] is not None
                else None,
                "subtask": observation["result"]["subtask"],
                "subtask_tokens": observation["result"]["subtask_tokens"].tolist()
                if observation["result"]["subtask_tokens"] is not None
                else None,
                "state": observation["result"]["state"].tolist()
                if observation["result"]["state"] is not None
                else None,
                "timing": observation["result"]["timing"],
            },
            "images_shape": observation["images_shape"],
            "state_shape": observation["state_shape"],
            "high_level_prompt": observation["high_level_prompt"],
            "low_level_prompt": observation["low_level_prompt"],
            "is_initial": observation.get("is_initial", False),
        }

        with open(output_file, "w") as f:
            json.dump(serializable_data, f, indent=2)

        logger.debug(f"è§‚å¯Ÿæ•°æ®å·²ä¿å­˜: {output_file}")


async def main():
    """æµ‹è¯• LeRobot æ¨ç†è§‚å¯Ÿå™¨"""
    # åˆ›å»ºè§‚å¯Ÿå™¨
    observer = LeRobotInferenceObserver(config_name="right_pi05_20", gpu_id=1, output_dir="./lerobot_inference_outputs")

    # æ·»åŠ è§‚å¯Ÿå›è°ƒ
    async def on_observation(data):
        logger.info("ğŸ“Š æ”¶åˆ°è§‚å¯Ÿæ•°æ®:")
        logger.info(f"   å¸§ç´¢å¼•: {data['frame_idx']}")
        logger.info(f"   æ¨ç†è€—æ—¶: {data['inference_time']:.3f}s")
        if data["result"].get("subtask"):
            logger.info(f"   å­ä»»åŠ¡: {data['result']['subtask']}")

    observer.add_observation_callback(on_observation)

    # åˆ›å»ºæ¨¡æ‹Ÿçš„ LeRobot æ•°æ®
    fake_episode = observer.create_fake_lerobot_data()

    try:
        # æµ‹è¯•å•æ¬¡æ¨ç†
        logger.info("=" * 60)
        logger.info("æµ‹è¯•å•æ¬¡æ¨ç†è§‚å¯Ÿ")
        logger.info("=" * 60)

        await observer.observe_single_inference(
            episode_data=fake_episode,
            frame_idx=0,
            high_level_prompt="Pick up the red block and place it in the box",
            low_level_prompt="Move to the block, grasp it, lift it up",
        )

        # æµ‹è¯•æŒç»­æ¨ç†
        logger.info("\n" + "=" * 60)
        logger.info("æµ‹è¯•æŒç»­æ¨ç†è§‚å¯Ÿ")
        logger.info("=" * 60)

        continuous_obs = await observer.observe_continuous_inference(
            episode_data=fake_episode,
            start_frame=0,
            max_frames=5,
            frame_interval=1.0,
            high_level_prompt="Organize the workspace",
            low_level_prompt="Sort items by category",
        )

        logger.info("\nğŸ“ˆ è§‚å¯Ÿæ€»ç»“:")
        logger.info("   å•æ¬¡æ¨ç†: æˆåŠŸ")
        logger.info(f"   æŒç»­æ¨ç†: {len(continuous_obs)} å¸§")
        logger.info(f"   è¾“å‡ºç›®å½•: {observer.output_dir}")

    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
